{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "83f8f5e8",
   "metadata": {},
   "source": [
    "# Feature Reduction using Bio Inspired Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4a3b8829",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "import warnings\n",
    "import time\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.resetwarnings()\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbc78368",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"/Users/saikarthik/Desktop/UROP/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a565507",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f246b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd6e0d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1841c68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea9e0843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.975562072336266\n"
     ]
    }
   ],
   "source": [
    "c0=0\n",
    "c1=0\n",
    "for i in  df[\"Label\"]:\n",
    "    if i== 0 :\n",
    "        c0=c0+1\n",
    "    elif i==1:\n",
    "        c1=c1+1\n",
    "print(c0/c1)            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f69ccd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    if df[column].dtype == 'object':  \n",
    "        df[column] = df[column].replace(to_replace='.*', value=0, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a40f30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [col for col in df.columns if df[col].nunique() == 1]\n",
    "df = df.drop(columns=cols_to_drop)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72f9f4eb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "873c4294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SrcBytes', 'DstBytes', 'SrcLoad', 'DstLoad', 'SIntPkt', 'DIntPkt',\n",
       "       'SIntPktAct', 'SrcJitter', 'DstJitter', 'sMaxPktSz', 'dMaxPktSz',\n",
       "       'sMinPktSz', 'Dur', 'TotPkts', 'TotBytes', 'Load', 'Loss', 'pLoss',\n",
       "       'pSrcLoss', 'pDstLoss', 'Rate', 'Packet_num', 'Temp', 'SpO2',\n",
       "       'Pulse_Rate', 'SYS', 'DIA', 'Heart_rate', 'Resp_Rate', 'ST', 'Label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "af190a5f",
   "metadata": {},
   "source": [
    "# Random Forest "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "70fa8059",
   "metadata": {},
   "source": [
    "### Before GA and HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9de059a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Time: 2.00 seconds\n",
      "Accuracy: 0.9347426470588235\n",
      "Precision: 0.981042654028436\n",
      "Recall: 0.49759615384615385\n",
      "F1-Score: 0.6602870813397129\n",
      "Confusion Matrix:\n",
      " [[2844    4]\n",
      " [ 209  207]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      2848\n",
      "           1       0.98      0.50      0.66       416\n",
      "\n",
      "    accuracy                           0.93      3264\n",
      "   macro avg       0.96      0.75      0.81      3264\n",
      "weighted avg       0.94      0.93      0.93      3264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('Label', axis=1)\n",
    "y = df['Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Execution Time: {execution_time:.2f} seconds\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1-Score:\", f1_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cba96561",
   "metadata": {},
   "source": [
    "### After applying Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995762db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X = df.drop('Label', axis=1)\n",
    "y = df['Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "population_size = 50\n",
    "generations = 100\n",
    "mutation_rate = 0.01\n",
    "\n",
    "def evaluate_features(features):\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X_train.iloc[:, features], y_train)\n",
    "    y_pred = clf.predict(X_test.iloc[:, features])\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "population = [np.random.choice([0, 1], size=X_train.shape[1]) for _ in range(population_size)]\n",
    "\n",
    "\n",
    "\n",
    "for generation in range(generations):\n",
    "    fitness_scores = [evaluate_features(individual) for individual in population]\n",
    "    num_parents = int(population_size * 0.2)\n",
    "    parents = np.argsort(fitness_scores)[-num_parents]\n",
    "    parents = parents.tolist()  \n",
    "    new_population = []\n",
    "    for _ in range(population_size - num_parents):\n",
    "        parent1 = population[np.random.choice(parents)]\n",
    "        parent2 = population[np.random.choice(parents)]\n",
    "        crossover_point = np.random.randint(0, X_train.shape[1])\n",
    "        child = np.hstack((parent1[:crossover_point], parent2[crossover_point:]))\n",
    "        mutation = np.random.rand(X_train.shape[1]) < mutation_rate\n",
    "        child = (child + mutation) % 2\n",
    "        new_population.append(child)\n",
    "    population = np.vstack((population[parents], new_population))\n",
    "\n",
    "best_individual = population[np.argmax(fitness_scores)]\n",
    "selected_features = np.where(best_individual == 1)[0]\n",
    "\n",
    "start_time_with_ga = time.time()\n",
    "clf_with_ga = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf_with_ga.fit(X_train.iloc[:, selected_features], y_train)\n",
    "y_pred_with_ga = clf_with_ga.predict(X_test.iloc[:, selected_features])\n",
    "end_time_with_ga = time.time()\n",
    "\n",
    "time_taken_with_ga = end_time_with_ga - start_time_with_ga\n",
    "\n",
    "confusion_matrix_with_ga = confusion_matrix(y_test, y_pred_with_ga)\n",
    "\n",
    "print(\"Time taken for Model with Genetic Algorithm Feature Selection:\", time_taken_with_ga, \"seconds\")\n",
    "\n",
    "\n",
    "print(\"\\nConfusion Matrix for Model with Genetic Algorithm Feature Selection:\")\n",
    "print(confusion_matrix_with_ga)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nConfusion Matrix for Model with Genetic Algorithm Feature Selection:\")\n",
    "print(confusion_matrix_with_ga)\n",
    "\n",
    "\n",
    "\n",
    "accuracy_with_ga = accuracy_score(y_test, y_pred_with_ga)\n",
    "precision_with_ga = precision_score(y_test, y_pred_with_ga)\n",
    "recall_with_ga = recall_score(y_test, y_pred_with_ga)\n",
    "f1_score_with_ga = f1_score(y_test, y_pred_with_ga)\n",
    "\n",
    "\n",
    "print(\"\\nModel with Genetic Algorithm Feature Selection Metrics:\")\n",
    "print(\"Accuracy (with GA):\", accuracy_with_ga)\n",
    "print(\"Precision (with GA):\", precision_with_ga)\n",
    "print(\"Recall (with GA):\", recall_with_ga)\n",
    "print(\"F1 Score (with GA):\", f1_score_with_ga)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "09104765",
   "metadata": {},
   "source": [
    "### After applying Hill climb on Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0022fc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: [0, 1, 2, 3, 10, 11, 12, 13, 14, 15, 18, 20, 21, 24, 25, 26, 27, 28, 29, 31, 32]\n",
      "Best Score: 0.9589460784313726\n",
      "Accuracy: 0.9589460784313726\n",
      "Precision: 0.9595113439439142\n",
      "Recall: 0.9589460784313726\n",
      "F1 Score: 0.9559702794086331\n",
      "Confusion Matrix:\n",
      " [[2840    8]\n",
      " [ 126  290]]\n",
      "Time taken: 2.0015292167663574 seconds\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('Label', axis=1)\n",
    "y = df['Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train.to_numpy()  \n",
    "X_test = X_test.to_numpy()  \n",
    "\n",
    "def objective_function(features):\n",
    "    start_time = time.time()\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X_train[:, features], y_train)\n",
    "    y_pred = clf.predict(X_test[:, features])\n",
    "    end_time = time.time()\n",
    "\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "def hill_climbing_feature_selection(num_features, num_iterations):\n",
    "    current_features = list(range(num_features))\n",
    "    current_score = objective_function(current_features)\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "        neighbor = current_features.copy()\n",
    "        if len(neighbor) > 1:  \n",
    "            feature_to_remove = random.choice(neighbor)\n",
    "            neighbor.remove(feature_to_remove)\n",
    "        else:\n",
    "            features_not_in_subset = list(set(range(num_features)) - set(neighbor))\n",
    "            if features_not_in_subset:\n",
    "                feature_to_add = random.choice(features_not_in_subset)\n",
    "                neighbor.append(feature_to_add)\n",
    "        neighbor_score = objective_function(neighbor)\n",
    "        if neighbor_score > current_score:\n",
    "            current_features = neighbor\n",
    "            current_score = neighbor_score\n",
    "\n",
    "    return current_features, current_score\n",
    "\n",
    "num_features = X_train.shape[1]\n",
    "num_iterations = 100\n",
    "\n",
    "selected_features, best_score = hill_climbing_feature_selection(num_features, num_iterations)\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train[:, selected_features], y_train)\n",
    "y_pred = clf.predict(X_test[:, selected_features])\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Selected Features:\", selected_features)\n",
    "print(\"Best Score:\", best_score)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Confusion Matrix:\\n\", confusion)\n",
    "print(\"Time taken:\", elapsed_time, \"seconds\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "93678390",
   "metadata": {},
   "source": [
    "# --------------------------------------------------\n",
    "# SVM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a69e33aa",
   "metadata": {},
   "source": [
    "### Before GA and HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15bf4d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Time (SVM): 364.24 seconds\n",
      "Accuracy (SVM): 0.9283088235294118\n",
      "Precision (SVM): 0.989247311827957\n",
      "Recall (SVM): 0.4423076923076923\n",
      "F1-Score (SVM): 0.6112956810631229\n",
      "Confusion Matrix (SVM):\n",
      " [[2846    2]\n",
      " [ 232  184]]\n",
      "Classification Report (SVM):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2848\n",
      "           1       0.99      0.44      0.61       416\n",
      "\n",
      "    accuracy                           0.93      3264\n",
      "   macro avg       0.96      0.72      0.79      3264\n",
      "weighted avg       0.93      0.93      0.92      3264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "precision_svm = precision_score(y_test, y_pred_svm)\n",
    "recall_svm = recall_score(y_test, y_pred_svm)\n",
    "f1_score_svm = f1_score(y_test, y_pred_svm)\n",
    "conf_matrix_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "classification_rep_svm = classification_report(y_test, y_pred_svm)\n",
    "\n",
    "print(f\"Execution Time (SVM): {execution_time:.2f} seconds\")\n",
    "print(\"Accuracy (SVM):\", accuracy_svm)\n",
    "print(\"Precision (SVM):\", precision_svm)\n",
    "print(\"Recall (SVM):\", recall_svm)\n",
    "print(\"F1-Score (SVM):\", f1_score_svm)\n",
    "print(\"Confusion Matrix (SVM):\\n\", conf_matrix_svm)\n",
    "print(\"Classification Report (SVM):\\n\", classification_rep_svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6fda57c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for Model with Genetic Algorithm Feature Selection: 478.169570684433 seconds\n",
      "\n",
      "Confusion Matrix for Model with Genetic Algorithm Feature Selection:\n",
      "[[2840    8]\n",
      " [ 234  182]]\n",
      "\n",
      "Model with Genetic Algorithm Feature Selection Metrics:\n",
      "Accuracy (with GA): 0.9258578431372549\n",
      "Precision (with GA): 0.9578947368421052\n",
      "Recall (with GA): 0.4375\n",
      "F1 Score (with GA): 0.6006600660066007\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('Label', axis=1)\n",
    "y = df['Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "population_size = 50\n",
    "generations = 100\n",
    "mutation_rate = 0.01\n",
    "\n",
    "def evaluate_features(features):\n",
    "    clf = SVC(kernel='linear', random_state=42)\n",
    "    clf.fit(X_train.iloc[:, features], y_train)\n",
    "    y_pred = clf.predict(X_test.iloc[:, features])\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "population = [np.random.choice([0, 1], size=X_train.shape[1]) for _ in range(population_size)]\n",
    "\n",
    "for generation in range(generations):\n",
    "    fitness_scores = [evaluate_features(individual) for individual in population]\n",
    "    num_parents = int(population_size * 0.2)\n",
    "    parents = np.argsort(fitness_scores)[-num_parents]\n",
    "    parents = parents.tolist()\n",
    "    new_population = []\n",
    "    for _ in range(population_size - num_parents):\n",
    "        parent1 = population[np.random.choice(parents)]\n",
    "        parent2 = population[np.random.choice(parents)]\n",
    "        crossover_point = np.random.randint(0, X_train.shape[1])\n",
    "        child = np.hstack((parent1[:crossover_point], parent2[crossover_point:]))\n",
    "        mutation = np.random.rand(X_train.shape[1]) < mutation_rate\n",
    "        child = (child + mutation) % 2\n",
    "        new_population.append(child)\n",
    "    population = np.vstack((population[parents], new_population))\n",
    "\n",
    "best_individual = population[np.argmax(fitness_scores)]\n",
    "selected_features = np.where(best_individual == 1)[0]\n",
    "\n",
    "start_time_with_ga = time.time()\n",
    "clf_with_ga = SVC(kernel='linear', random_state=42)\n",
    "clf_with_ga.fit(X_train.iloc[:, selected_features], y_train)\n",
    "y_pred_with_ga = clf_with_ga.predict(X_test.iloc[:, selected_features])\n",
    "end_time_with_ga = time.time()\n",
    "\n",
    "time_taken_with_ga = end_time_with_ga - start_time_with_ga\n",
    "\n",
    "confusion_matrix_with_ga = confusion_matrix(y_test, y_pred_with_ga)\n",
    "\n",
    "print(\"Time taken for Model with Genetic Algorithm Feature Selection:\", time_taken_with_ga, \"seconds\")\n",
    "\n",
    "print(\"\\nConfusion Matrix for Model with Genetic Algorithm Feature Selection:\")\n",
    "print(confusion_matrix_with_ga)\n",
    "\n",
    "accuracy_with_ga = accuracy_score(y_test, y_pred_with_ga)\n",
    "precision_with_ga = precision_score(y_test, y_pred_with_ga)\n",
    "recall_with_ga = recall_score(y_test, y_pred_with_ga)\n",
    "f1_score_with_ga = f1_score(y_test, y_pred_with_ga)\n",
    "\n",
    "print(\"\\nModel with Genetic Algorithm Feature Selection Metrics:\")\n",
    "print(\"Accuracy (with GA):\", accuracy_with_ga)\n",
    "print(\"Precision (with GA):\", precision_with_ga)\n",
    "print(\"Recall (with GA):\", recall_with_ga)\n",
    "print(\"F1 Score (with GA):\", f1_score_with_ga)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b1f368c",
   "metadata": {},
   "source": [
    "### After Hill Climb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4144a359",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/saikarthik/Desktop/UROP/UROP.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 41>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/saikarthik/Desktop/UROP/UROP.ipynb#X35sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m num_features \u001b[39m=\u001b[39m X_train\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/saikarthik/Desktop/UROP/UROP.ipynb#X35sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m num_iterations \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/saikarthik/Desktop/UROP/UROP.ipynb#X35sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m selected_features, best_score \u001b[39m=\u001b[39m hill_climbing_feature_selection(num_features, num_iterations)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/saikarthik/Desktop/UROP/UROP.ipynb#X35sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/saikarthik/Desktop/UROP/UROP.ipynb#X35sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m elapsed_time \u001b[39m=\u001b[39m end_time \u001b[39m-\u001b[39m start_time\n",
      "\u001b[1;32m/Users/saikarthik/Desktop/UROP/UROP.ipynb Cell 23\u001b[0m in \u001b[0;36mhill_climbing_feature_selection\u001b[0;34m(num_features, num_iterations)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/saikarthik/Desktop/UROP/UROP.ipynb#X35sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m         feature_to_add \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39mchoice(features_not_in_subset)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/saikarthik/Desktop/UROP/UROP.ipynb#X35sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m         neighbor\u001b[39m.\u001b[39mappend(feature_to_add)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/saikarthik/Desktop/UROP/UROP.ipynb#X35sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m neighbor_score \u001b[39m=\u001b[39m objective_function(neighbor)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/saikarthik/Desktop/UROP/UROP.ipynb#X35sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mif\u001b[39;00m neighbor_score \u001b[39m>\u001b[39m current_score:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/saikarthik/Desktop/UROP/UROP.ipynb#X35sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     current_features \u001b[39m=\u001b[39m neighbor\n",
      "\u001b[1;32m/Users/saikarthik/Desktop/UROP/UROP.ipynb Cell 23\u001b[0m in \u001b[0;36mobjective_function\u001b[0;34m(features)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/saikarthik/Desktop/UROP/UROP.ipynb#X35sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mobjective_function\u001b[39m(features):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/saikarthik/Desktop/UROP/UROP.ipynb#X35sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     clf \u001b[39m=\u001b[39m SVC(kernel\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlinear\u001b[39m\u001b[39m'\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)  \u001b[39m# Use linear kernel for SVM\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/saikarthik/Desktop/UROP/UROP.ipynb#X35sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     clf\u001b[39m.\u001b[39;49mfit(X_train[:, features], y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/saikarthik/Desktop/UROP/UROP.ipynb#X35sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     y_pred \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mpredict(X_test[:, features])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/saikarthik/Desktop/UROP/UROP.ipynb#X35sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m accuracy_score(y_test, y_pred)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m[LibSVM]\u001b[39m\u001b[39m\"\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    254\u001b[0m seed \u001b[39m=\u001b[39m rnd\u001b[39m.\u001b[39mrandint(np\u001b[39m.\u001b[39miinfo(\u001b[39m\"\u001b[39m\u001b[39mi\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mmax)\n\u001b[0;32m--> 255\u001b[0m fit(X, y, sample_weight, solver_type, kernel, random_seed\u001b[39m=\u001b[39;49mseed)\n\u001b[1;32m    256\u001b[0m \u001b[39m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape_fit_ \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(X, \u001b[39m\"\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:315\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    302\u001b[0m libsvm\u001b[39m.\u001b[39mset_verbosity_wrap(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[1;32m    304\u001b[0m \u001b[39m# we don't pass **self.get_params() to allow subclasses to\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[39m# add other parameters to __init__\u001b[39;00m\n\u001b[1;32m    306\u001b[0m (\n\u001b[1;32m    307\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupport_,\n\u001b[1;32m    308\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupport_vectors_,\n\u001b[1;32m    309\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_support,\n\u001b[1;32m    310\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdual_coef_,\n\u001b[1;32m    311\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_,\n\u001b[1;32m    312\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_probA,\n\u001b[1;32m    313\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_probB,\n\u001b[1;32m    314\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_status_,\n\u001b[0;32m--> 315\u001b[0m ) \u001b[39m=\u001b[39m libsvm\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    316\u001b[0m     X,\n\u001b[1;32m    317\u001b[0m     y,\n\u001b[1;32m    318\u001b[0m     svm_type\u001b[39m=\u001b[39;49msolver_type,\n\u001b[1;32m    319\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    320\u001b[0m     class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight_,\n\u001b[1;32m    321\u001b[0m     kernel\u001b[39m=\u001b[39;49mkernel,\n\u001b[1;32m    322\u001b[0m     C\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mC,\n\u001b[1;32m    323\u001b[0m     nu\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnu,\n\u001b[1;32m    324\u001b[0m     probability\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprobability,\n\u001b[1;32m    325\u001b[0m     degree\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdegree,\n\u001b[1;32m    326\u001b[0m     shrinking\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshrinking,\n\u001b[1;32m    327\u001b[0m     tol\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[1;32m    328\u001b[0m     cache_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcache_size,\n\u001b[1;32m    329\u001b[0m     coef0\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcoef0,\n\u001b[1;32m    330\u001b[0m     gamma\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_gamma,\n\u001b[1;32m    331\u001b[0m     epsilon\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepsilon,\n\u001b[1;32m    332\u001b[0m     max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[1;32m    333\u001b[0m     random_seed\u001b[39m=\u001b[39;49mrandom_seed,\n\u001b[1;32m    334\u001b[0m )\n\u001b[1;32m    336\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_warn_from_fit_status()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X = df.drop('Label', axis=1)\n",
    "y = df['Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "def objective_function(features):\n",
    "    clf = SVC(kernel='linear', random_state=42)  \n",
    "    clf.fit(X_train[:, features], y_train)\n",
    "    y_pred = clf.predict(X_test[:, features])\n",
    "\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "def hill_climbing_feature_selection(num_features, num_iterations):\n",
    "    current_features = list(range(num_features))\n",
    "    current_score = objective_function(current_features)\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "        neighbor = current_features.copy()\n",
    "        if len(neighbor) > 1:\n",
    "            feature_to_remove = random.choice(neighbor)\n",
    "            neighbor.remove(feature_to_remove)\n",
    "        else:\n",
    "            features_not_in_subset = list(set(range(num_features)) - set(neighbor))\n",
    "            if features_not_in_subset:\n",
    "                feature_to_add = random.choice(features_not_in_subset)\n",
    "                neighbor.append(feature_to_add)\n",
    "        neighbor_score = objective_function(neighbor)\n",
    "        if neighbor_score > current_score:\n",
    "            current_features = neighbor\n",
    "            current_score = neighbor_score\n",
    "\n",
    "    return current_features, current_score\n",
    "\n",
    "num_features = X_train.shape[1]\n",
    "num_iterations = 100\n",
    "\n",
    "selected_features, best_score = hill_climbing_feature_selection(num_features, num_iterations)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "clf = SVC(kernel='linear', random_state=42) \n",
    "clf.fit(X_train[:, selected_features], y_train)\n",
    "y_pred = clf.predict(X_test[:, selected_features])\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Selected Features:\", selected_features)\n",
    "print(\"Best Score:\", best_score)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Confusion Matrix:\\n\", confusion)\n",
    "print(\"Time taken:\", elapsed_time, \"seconds\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8019ecec",
   "metadata": {},
   "source": [
    "# -------------------------------------\n",
    "# Naive Bayes\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "afc6df7e",
   "metadata": {},
   "source": [
    "### Before GA and HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d428319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Time: 0.01 seconds\n",
      "Accuracy: 0.8927696078431373\n",
      "Precision: 0.6044303797468354\n",
      "Recall: 0.45913461538461536\n",
      "F1-Score: 0.5218579234972678\n",
      "Confusion Matrix:\n",
      " [[2723  125]\n",
      " [ 225  191]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94      2848\n",
      "           1       0.60      0.46      0.52       416\n",
      "\n",
      "    accuracy                           0.89      3264\n",
      "   macro avg       0.76      0.71      0.73      3264\n",
      "weighted avg       0.88      0.89      0.89      3264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('Label', axis=1)\n",
    "y = df['Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = GaussianNB()\n",
    "\n",
    "start_time = time.time()\n",
    "clf.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Execution Time: {execution_time:.2f} seconds\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1-Score:\", f1_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "607e7287",
   "metadata": {},
   "source": [
    "### After applying GA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ca6cf3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for Model with Genetic Algorithm Feature Selection: 0.004553318023681641 seconds\n",
      "\n",
      "Confusion Matrix for Model with Genetic Algorithm Feature Selection:\n",
      "[[2837   11]\n",
      " [ 237  179]]\n",
      "\n",
      "Model with Genetic Algorithm Feature Selection Metrics:\n",
      "Accuracy (with GA): 0.9240196078431373\n",
      "Precision (with GA): 0.9421052631578948\n",
      "Recall (with GA): 0.43028846153846156\n",
      "F1 Score (with GA): 0.5907590759075908\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('Label', axis=1)\n",
    "y = df['Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "population_size = 50\n",
    "generations = 100\n",
    "mutation_rate = 0.01\n",
    "\n",
    "def evaluate_features(features):\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(X_train.iloc[:, features], y_train)\n",
    "    y_pred = clf.predict(X_test.iloc[:, features])\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "population = [np.random.choice([0, 1], size=X_train.shape[1]) for _ in range(population_size)]\n",
    "\n",
    "for generation in range(generations):\n",
    "    fitness_scores = [evaluate_features(individual) for individual in population]\n",
    "    num_parents = int(population_size * 0.2)\n",
    "    parents = [population[i] for i in np.argsort(fitness_scores)[-num_parents:]]\n",
    "    new_population = []\n",
    "    for _ in range(population_size - num_parents):\n",
    "        parent1 = population[np.random.choice(num_parents)]\n",
    "        parent2 = population[np.random.choice(num_parents)]\n",
    "        crossover_point = np.random.randint(0, X_train.shape[1])\n",
    "        child = np.hstack((parent1[:crossover_point], parent2[crossover_point:]))\n",
    "        mutation = np.random.rand(X_train.shape[1]) < mutation_rate\n",
    "        child = (child + mutation) % 2\n",
    "        new_population.append(child)\n",
    "    population = np.vstack((parents, new_population))\n",
    "\n",
    "best_individual = population[np.argmax(fitness_scores)]\n",
    "selected_features = np.where(best_individual == 1)[0]\n",
    "\n",
    "start_time_with_ga = time.time()\n",
    "clf_with_ga = GaussianNB()\n",
    "clf_with_ga.fit(X_train.iloc[:, selected_features], y_train)\n",
    "y_pred_with_ga = clf_with_ga.predict(X_test.iloc[:, selected_features])\n",
    "end_time_with_ga = time.time()\n",
    "\n",
    "time_taken_with_ga = end_time_with_ga - start_time_with_ga\n",
    "\n",
    "confusion_matrix_with_ga = confusion_matrix(y_test, y_pred_with_ga)\n",
    "\n",
    "print(\"Time taken for Model with Genetic Algorithm Feature Selection:\", time_taken_with_ga, \"seconds\")\n",
    "\n",
    "print(\"\\nConfusion Matrix for Model with Genetic Algorithm Feature Selection:\")\n",
    "print(confusion_matrix_with_ga)\n",
    "\n",
    "accuracy_with_ga = accuracy_score(y_test, y_pred_with_ga)\n",
    "precision_with_ga = precision_score(y_test, y_pred_with_ga)\n",
    "recall_with_ga = recall_score(y_test, y_pred_with_ga)\n",
    "f1_score_with_ga = f1_score(y_test, y_pred_with_ga)\n",
    "\n",
    "print(\"\\nModel with Genetic Algorithm Feature Selection Metrics:\")\n",
    "print(\"Accuracy (with GA):\", accuracy_with_ga)\n",
    "print(\"Precision (with GA):\", precision_with_ga)\n",
    "print(\"Recall (with GA):\", recall_with_ga)\n",
    "print(\"F1 Score (with GA):\", f1_score_with_ga)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a029739",
   "metadata": {},
   "source": [
    "### After applying HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f13fc187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: [0, 1, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29]\n",
      "Best Score: 0.9264705882352942\n",
      "Accuracy: 0.9264705882352942\n",
      "Precision: 0.9277485727928918\n",
      "Recall: 0.9264705882352942\n",
      "F1 Score: 0.9147725303016352\n",
      "Confusion Matrix:\n",
      " [[2837   11]\n",
      " [ 229  187]]\n",
      "Time taken: 0.307614803314209 seconds\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('Label', axis=1)\n",
    "y = df['Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "def objective_function(features):\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(X_train[:, features], y_train)\n",
    "    y_pred = clf.predict(X_test[:, features])\n",
    "\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "def hill_climbing_feature_selection(num_features, num_iterations):\n",
    "    current_features = list(range(num_features))\n",
    "    current_score = objective_function(current_features)\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "        neighbor = current_features.copy()\n",
    "        if len(neighbor) > 1:\n",
    "            feature_to_remove = random.choice(neighbor)\n",
    "            neighbor.remove(feature_to_remove)\n",
    "        else:\n",
    "            features_not_in_subset = list(set(range(num_features)) - set(neighbor))\n",
    "            if features_not_in_subset:\n",
    "                feature_to_add = random.choice(features_not_in_subset)\n",
    "                neighbor.append(feature_to_add)\n",
    "        neighbor_score = objective_function(neighbor)\n",
    "        if neighbor_score > current_score:\n",
    "            current_features = neighbor\n",
    "            current_score = neighbor_score\n",
    "\n",
    "    return current_features, current_score\n",
    "\n",
    "num_features = X_train.shape[1]\n",
    "num_iterations = 100\n",
    "\n",
    "selected_features, best_score = hill_climbing_feature_selection(num_features, num_iterations)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train[:, selected_features], y_train)\n",
    "y_pred = clf.predict(X_test[:, selected_features])\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Selected Features:\", selected_features)\n",
    "print(\"Best Score:\", best_score)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Confusion Matrix:\\n\", confusion)\n",
    "print(\"Time taken:\", elapsed_time, \"seconds\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9358113f",
   "metadata": {},
   "source": [
    "### After applying GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fdc72f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for Model with Genetic Algorithm Feature Selection: 0.0034110546112060547 seconds\n",
      "\n",
      "Confusion Matrix for Model with Genetic Algorithm Feature Selection:\n",
      "[[2835   13]\n",
      " [ 401   15]]\n",
      "\n",
      "Model with Genetic Algorithm Feature Selection Metrics:\n",
      "Accuracy (with GA): 0.8731617647058824\n",
      "Precision (with GA): 0.5357142857142857\n",
      "Recall (with GA): 0.036057692307692304\n",
      "F1 Score (with GA): 0.06756756756756756\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "population_size = 50\n",
    "generations = 100\n",
    "mutation_rate = 0.01\n",
    "\n",
    "def evaluate_features(features):\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(X_train.iloc[:, features], y_train)\n",
    "    y_pred = clf.predict(X_test.iloc[:, features])\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "population = [np.random.choice([0, 1], size=X_train.shape[1]) for _ in range(population_size)]\n",
    "\n",
    "for generation in range(generations):\n",
    "    fitness_scores = [evaluate_features(individual) for individual in population]\n",
    "    num_parents = int(population_size * 0.2)\n",
    "    parents = [population[i] for i in np.argsort(fitness_scores)[-num_parents:]]\n",
    "    new_population = []\n",
    "    for _ in range(population_size - num_parents):\n",
    "        parent1 = population[np.random.choice(num_parents)]\n",
    "        parent2 = population[np.random.choice(num_parents)]\n",
    "        crossover_point = np.random.randint(0, X_train.shape[1])\n",
    "        child = np.hstack((parent1[:crossover_point], parent2[crossover_point:]))\n",
    "        mutation = np.random.rand(X_train.shape[1]) < mutation_rate\n",
    "        child = (child + mutation) % 2\n",
    "        new_population.append(child)\n",
    "    population = np.vstack((parents, new_population))\n",
    "\n",
    "best_individual = population[np.argmax(fitness_scores)]\n",
    "selected_features = np.where(best_individual == 1)[0]\n",
    "\n",
    "start_time_with_ga = time.time()\n",
    "clf_with_ga = GaussianNB()\n",
    "clf_with_ga.fit(X_train.iloc[:, selected_features], y_train)\n",
    "y_pred_with_ga = clf_with_ga.predict(X_test.iloc[:, selected_features])\n",
    "end_time_with_ga = time.time()\n",
    "\n",
    "time_taken_with_ga = end_time_with_ga - start_time_with_ga\n",
    "\n",
    "confusion_matrix_with_ga = confusion_matrix(y_test, y_pred_with_ga)\n",
    "\n",
    "print(\"Time taken for Model with Genetic Algorithm Feature Selection:\", time_taken_with_ga, \"seconds\")\n",
    "\n",
    "print(\"\\nConfusion Matrix for Model with Genetic Algorithm Feature Selection:\")\n",
    "print(confusion_matrix_with_ga)\n",
    "\n",
    "accuracy_with_ga = accuracy_score(y_test, y_pred_with_ga)\n",
    "precision_with_ga = precision_score(y_test, y_pred_with_ga)\n",
    "recall_with_ga = recall_score(y_test, y_pred_with_ga)\n",
    "f1_score_with_ga = f1_score(y_test, y_pred_with_ga)\n",
    "\n",
    "print(\"\\nModel with Genetic Algorithm Feature Selection Metrics:\")\n",
    "print(\"Accuracy (with GA):\", accuracy_with_ga)\n",
    "print(\"Precision (with GA):\", precision_with_ga)\n",
    "print(\"Recall (with GA):\", recall_with_ga)\n",
    "print(\"F1 Score (with GA):\", f1_score_with_ga)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f96b4ce",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "221f69cd",
   "metadata": {},
   "source": [
    "### Before GA and HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "060fdb74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Time: 0.18 seconds\n",
      "Accuracy: 0.9451593137254902\n",
      "Precision: 0.7925925925925926\n",
      "Recall: 0.7716346153846154\n",
      "F1-Score: 0.781973203410475\n",
      "Confusion Matrix:\n",
      " [[2764   84]\n",
      " [  95  321]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      2848\n",
      "           1       0.79      0.77      0.78       416\n",
      "\n",
      "    accuracy                           0.95      3264\n",
      "   macro avg       0.88      0.87      0.88      3264\n",
      "weighted avg       0.94      0.95      0.94      3264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('Label', axis=1)\n",
    "y = df['Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "start_time = time.time()\n",
    "clf.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Execution Time: {execution_time:.2f} seconds\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1-Score:\", f1_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Classification Report:\\n\", classification_rep)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "94acf8f1",
   "metadata": {},
   "source": [
    "### After applying Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d1156ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for Model with Genetic Algorithm Feature Selection: 0.10251116752624512 seconds\n",
      "\n",
      "Confusion Matrix for Model with Genetic Algorithm Feature Selection:\n",
      "[[2751   97]\n",
      " [ 102  314]]\n",
      "\n",
      "Model with Genetic Algorithm Feature Selection Metrics:\n",
      "Accuracy (with GA): 0.9390318627450981\n",
      "Precision (with GA): 0.7639902676399026\n",
      "Recall (with GA): 0.7548076923076923\n",
      "F1 Score (with GA): 0.7593712212817413\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('Label', axis=1)\n",
    "y = df['Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "population_size = 50\n",
    "generations = 100\n",
    "mutation_rate = 0.01\n",
    "\n",
    "def evaluate_features(features):\n",
    "    clf = DecisionTreeClassifier(random_state=42)\n",
    "    clf.fit(X_train.iloc[:, features], y_train)\n",
    "    y_pred = clf.predict(X_test.iloc[:, features])\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "population = [np.random.choice([0, 1], size=X_train.shape[1]) for _ in range(population_size)]\n",
    "\n",
    "for generation in range(generations):\n",
    "    fitness_scores = [evaluate_features(individual) for individual in population]\n",
    "    num_parents = int(population_size * 0.2)\n",
    "    parents = np.argsort(fitness_scores)[-num_parents]\n",
    "    parents = parents.tolist()\n",
    "    new_population = []\n",
    "    for _ in range(population_size - num_parents):\n",
    "        parent1 = population[np.random.choice(parents)]\n",
    "        parent2 = population[np.random.choice(parents)]\n",
    "        crossover_point = np.random.randint(0, X_train.shape[1])\n",
    "        child = np.hstack((parent1[:crossover_point], parent2[crossover_point:]))\n",
    "        mutation = np.random.rand(X_train.shape[1]) < mutation_rate\n",
    "        child = (child + mutation) % 2\n",
    "        new_population.append(child)\n",
    "    population = np.vstack((population[parents], new_population))\n",
    "\n",
    "best_individual = population[np.argmax(fitness_scores)]\n",
    "selected_features = np.where(best_individual == 1)[0]\n",
    "\n",
    "start_time_with_ga = time.time()\n",
    "clf_with_ga = DecisionTreeClassifier(random_state=42)\n",
    "clf_with_ga.fit(X_train.iloc[:, selected_features], y_train)\n",
    "y_pred_with_ga = clf_with_ga.predict(X_test.iloc[:, selected_features])\n",
    "end_time_with_ga = time.time()\n",
    "\n",
    "time_taken_with_ga = end_time_with_ga - start_time_with_ga\n",
    "\n",
    "confusion_matrix_with_ga = confusion_matrix(y_test, y_pred_with_ga)\n",
    "\n",
    "print(\"Time taken for Model with Genetic Algorithm Feature Selection:\", time_taken_with_ga, \"seconds\")\n",
    "\n",
    "print(\"\\nConfusion Matrix for Model with Genetic Algorithm Feature Selection:\")\n",
    "print(confusion_matrix_with_ga)\n",
    "\n",
    "accuracy_with_ga = accuracy_score(y_test, y_pred_with_ga)\n",
    "precision_with_ga = precision_score(y_test, y_pred_with_ga)\n",
    "recall_with_ga = recall_score(y_test, y_pred_with_ga)\n",
    "f1_score_with_ga = f1_score(y_test, y_pred_with_ga)\n",
    "\n",
    "print(\"\\nModel with Genetic Algorithm Feature Selection Metrics:\")\n",
    "print(\"Accuracy (with GA):\", accuracy_with_ga)\n",
    "print(\"Precision (with GA):\", precision_with_ga)\n",
    "print(\"Recall (with GA):\", recall_with_ga)\n",
    "print(\"F1 Score (with GA):\", f1_score_with_ga)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f014ced",
   "metadata": {},
   "source": [
    "### After applying HC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "658e0002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29]\n",
      "Best Score: 0.9509803921568627\n",
      "Accuracy: 0.9322916666666666\n",
      "Precision: 0.9342922223446857\n",
      "Recall: 0.9322916666666666\n",
      "F1 Score: 0.922399009493971\n",
      "Confusion Matrix:\n",
      " [[2840    8]\n",
      " [ 213  203]]\n",
      "Time taken: 0.6461198329925537 seconds\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('Label', axis=1)\n",
    "y = df['Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "\n",
    "def objective_function(features):\n",
    "    start_time = time.time()\n",
    "    clf = DecisionTreeClassifier(random_state=42)\n",
    "    clf.fit(X_train[:, features], y_train)\n",
    "    y_pred = clf.predict(X_test[:, features])\n",
    "    end_time = time.time()\n",
    "\n",
    "    return accuracy_score(y_test, y_pred), start_time, end_time\n",
    "\n",
    "def hill_climbing_feature_selection(num_features, num_iterations):\n",
    "    current_features = list(range(num_features))\n",
    "    current_score, start_time, _ = objective_function(current_features)  # Get start_time\n",
    "    \n",
    "    for _ in range(num_iterations):\n",
    "        neighbor = current_features.copy()\n",
    "        if len(neighbor) > 1:\n",
    "            feature_to_remove = random.choice(neighbor)\n",
    "            neighbor.remove(feature_to_remove)\n",
    "        else:\n",
    "            features_not_in_subset = list(set(range(num_features)) - set(neighbor))\n",
    "            if features_not_in_subset:\n",
    "                feature_to_add = random.choice(features_not_in_subset)\n",
    "                neighbor.append(feature_to_add)\n",
    "        neighbor_score, _, end_time = objective_function(neighbor)  # Get end_time\n",
    "        if neighbor_score > current_score:\n",
    "            current_features = neighbor\n",
    "            current_score = neighbor_score\n",
    "            elapsed_time = end_time - start_time  # Calculate elapsed_time\n",
    "\n",
    "    return current_features, current_score, elapsed_time  # Return elapsed_time\n",
    "\n",
    "num_features = X_train.shape[1]\n",
    "num_iterations = 100\n",
    "\n",
    "selected_features, best_score, elapsed_time = hill_climbing_feature_selection(num_features, num_iterations)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train[:, selected_features], y_train)\n",
    "y_pred = clf.predict(X_test[:, selected_features])\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Selected Features:\", selected_features)\n",
    "print(\"Best Score:\", best_score)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Confusion Matrix:\\n\", confusion)\n",
    "print(\"Time taken:\", elapsed_time, \"seconds\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7f5ee444",
   "metadata": {},
   "source": [
    "### ----------------------------------------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52c6b66b",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ad8c081",
   "metadata": {},
   "source": [
    "### Before applying GA and HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79f9cc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Time: 3.44 seconds\n",
      "Accuracy: 0.9283088235294118\n",
      "Precision: 0.9789473684210527\n",
      "Recall: 0.44711538461538464\n",
      "F1-Score: 0.6138613861386139\n",
      "Confusion Matrix:\n",
      " [[2844    4]\n",
      " [ 230  186]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      2848\n",
      "           1       0.98      0.45      0.61       416\n",
      "\n",
      "    accuracy                           0.93      3264\n",
      "   macro avg       0.95      0.72      0.79      3264\n",
      "weighted avg       0.93      0.93      0.92      3264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('Label', axis=1)\n",
    "y = df['Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "\n",
    "start_time = time.time()\n",
    "clf.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Execution Time: {execution_time:.2f} seconds\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1-Score:\", f1_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Classification Report:\\n\", classification_rep)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c95094c",
   "metadata": {},
   "source": [
    "### After applying GA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa7754fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for Model with Genetic Algorithm Feature Selection: 0.09711575508117676 seconds\n",
      "\n",
      "Confusion Matrix for Model with Genetic Algorithm Feature Selection:\n",
      "[[2834   14]\n",
      " [ 228  188]]\n",
      "\n",
      "Model with Genetic Algorithm Feature Selection Metrics (Logistic Regression):\n",
      "Accuracy (with GA): 0.9258578431372549\n",
      "Precision (with GA): 0.9306930693069307\n",
      "Recall (with GA): 0.4519230769230769\n",
      "F1 Score (with GA): 0.6084142394822006\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('Label', axis=1)\n",
    "y = df['Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "population_size = 50\n",
    "generations = 100\n",
    "mutation_rate = 0.01\n",
    "\n",
    "def evaluate_features(features):\n",
    "    clf = DecisionTreeClassifier(random_state=42)\n",
    "    clf.fit(X_train.iloc[:, features], y_train)\n",
    "    y_pred = clf.predict(X_test.iloc[:, features])\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "population = [np.random.choice([0, 1], size=X_train.shape[1]) for _ in range(population_size)]\n",
    "\n",
    "for generation in range(generations):\n",
    "    fitness_scores = [evaluate_features(individual) for individual in population]\n",
    "    num_parents = int(population_size * 0.2)\n",
    "    parents = np.argsort(fitness_scores)[-num_parents]\n",
    "    parents = parents.tolist()\n",
    "    new_population = []\n",
    "    for _ in range(population_size - num_parents):\n",
    "        parent1 = population[np.random.choice(parents)]\n",
    "        parent2 = population[np.random.choice(parents)]\n",
    "        crossover_point = np.random.randint(0, X_train.shape[1])\n",
    "        child = np.hstack((parent1[:crossover_point], parent2[crossover_point:]))\n",
    "        mutation = np.random.rand(X_train.shape[1]) < mutation_rate\n",
    "        child = (child + mutation) % 2\n",
    "        new_population.append(child)\n",
    "    population = np.vstack((population[parents], new_population))\n",
    "\n",
    "best_individual = population[np.argmax(fitness_scores)]\n",
    "selected_features = np.where(best_individual == 1)[0]\n",
    "start_time_with_ga = time.time()\n",
    "clf_with_ga = LogisticRegression(random_state=42)\n",
    "clf_with_ga.fit(X_train.iloc[:, selected_features], y_train)\n",
    "y_pred_with_ga = clf_with_ga.predict(X_test.iloc[:, selected_features])\n",
    "end_time_with_ga = time.time()\n",
    "\n",
    "time_taken_with_ga = end_time_with_ga - start_time_with_ga\n",
    "\n",
    "confusion_matrix_with_ga = confusion_matrix(y_test, y_pred_with_ga)\n",
    "\n",
    "print(\"Time taken for Model with Genetic Algorithm Feature Selection:\", time_taken_with_ga, \"seconds\")\n",
    "\n",
    "print(\"\\nConfusion Matrix for Model with Genetic Algorithm Feature Selection:\")\n",
    "print(confusion_matrix_with_ga)\n",
    "\n",
    "accuracy_with_ga = accuracy_score(y_test, y_pred_with_ga)\n",
    "precision_with_ga = precision_score(y_test, y_pred_with_ga)\n",
    "recall_with_ga = recall_score(y_test, y_pred_with_ga)\n",
    "f1_score_with_ga = f1_score(y_test, y_pred_with_ga)\n",
    "\n",
    "print(\"\\nModel with Genetic Algorithm Feature Selection Metrics (Logistic Regression):\")\n",
    "print(\"Accuracy (with GA):\", accuracy_with_ga)\n",
    "print(\"Precision (with GA):\", precision_with_ga)\n",
    "print(\"Recall (with GA):\", recall_with_ga)\n",
    "print(\"F1 Score (with GA):\", f1_score_with_ga)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After applying HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c35f9da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
      "Best Score: 0.928921568627451\n",
      "Accuracy: 0.9286151960784313\n",
      "Precision: 0.9331319078876861\n",
      "Recall: 0.9286151960784313\n",
      "F1 Score: 0.9164398739322334\n",
      "Confusion Matrix:\n",
      " [[2846    2]\n",
      " [ 231  185]]\n",
      "Time taken: 15.794579982757568 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saikarthik/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('Label', axis=1)\n",
    "y = df['Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "\n",
    "def objective_function(features):\n",
    "    clf = LogisticRegression(random_state=42, max_iter=100000)  # Increased max_iter\n",
    "    clf.fit(X_train[:, features], y_train)\n",
    "    y_pred = clf.predict(X_test[:, features])\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "def hill_climbing_feature_selection(num_features, num_iterations):\n",
    "    current_features = list(range(num_features))\n",
    "    current_score = objective_function(current_features)\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "        neighbor = current_features.copy()\n",
    "        if len(neighbor) > 1:  \n",
    "            feature_to_remove = random.choice(neighbor)\n",
    "            neighbor.remove(feature_to_remove)\n",
    "        else:\n",
    "            features_not_in_subset = list(set(range(num_features)) - set(neighbor))\n",
    "            if features_not_in_subset:\n",
    "                feature_to_add = random.choice(features_not_in_subset)\n",
    "                neighbor.append(feature_to_add)\n",
    "        neighbor_score = objective_function(neighbor)\n",
    "        if neighbor_score > current_score:\n",
    "            current_features = neighbor\n",
    "            current_score = neighbor_score\n",
    "\n",
    "    return current_features, current_score\n",
    "\n",
    "num_features = X_train.shape[1]\n",
    "num_iterations = 100\n",
    "\n",
    "# Feature Selection\n",
    "start_time = time.time()\n",
    "selected_features, best_score = hill_climbing_feature_selection(num_features, num_iterations)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# Classifier Training and Evaluation\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(X_train[:, selected_features], y_train)\n",
    "y_pred = clf.predict(X_test[:, selected_features])\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print Results\n",
    "print(\"Selected Features:\", selected_features)\n",
    "print(\"Best Score:\", best_score)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Confusion Matrix:\\n\", confusion)\n",
    "print(\"Time taken:\", elapsed_time, \"seconds\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d6805f2",
   "metadata": {},
   "source": [
    "# K nearest Neighbours "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6b54f2f",
   "metadata": {},
   "source": [
    "### Before applying GA and HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a964329f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Time: 0.00 seconds\n",
      "Accuracy: 0.9200367647058824\n",
      "Precision: 0.8506787330316742\n",
      "Recall: 0.4519230769230769\n",
      "F1-Score: 0.5902668759811617\n",
      "Confusion Matrix:\n",
      " [[2815   33]\n",
      " [ 228  188]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      2848\n",
      "           1       0.85      0.45      0.59       416\n",
      "\n",
      "    accuracy                           0.92      3264\n",
      "   macro avg       0.89      0.72      0.77      3264\n",
      "weighted avg       0.92      0.92      0.91      3264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = df.drop('Label', axis=1)\n",
    "y = df['Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=5)  \n",
    "\n",
    "start_time = time.time()\n",
    "clf.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Execution Time: {execution_time:.2f} seconds\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1-Score:\", f1_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Classification Report:\\n\", classification_rep)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9eb4d4c7",
   "metadata": {},
   "source": [
    "### After applying GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dff0cf8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Time: 0.0015380382537841797 seconds\n",
      "Accuracy: 0.9206495098039216\n",
      "Precision: 0.852017937219731\n",
      "Recall: 0.4567307692307692\n",
      "F1 Score: 0.594679186228482\n",
      "Confusion Matrix:\n",
      " [[2815   33]\n",
      " [ 226  190]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = df.drop('Label', axis=1)\n",
    "y = df['Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "population_size = 50\n",
    "generations = 100\n",
    "mutation_rate = 0.01\n",
    "\n",
    "def evaluate_features(features):\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X_train.iloc[:, features], y_train)\n",
    "    y_pred = clf.predict(X_test.iloc[:, features])\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "population = [np.random.choice([0, 1], size=X_train.shape[1]) for _ in range(population_size)]\n",
    "\n",
    "\n",
    "\n",
    "for generation in range(generations):\n",
    "    fitness_scores = [evaluate_features(individual) for individual in population]\n",
    "    num_parents = int(population_size * 0.2)\n",
    "    parents = np.argsort(fitness_scores)[-num_parents]\n",
    "    parents = parents.tolist()  \n",
    "    new_population = []\n",
    "    for _ in range(population_size - num_parents):\n",
    "        parent1 = population[np.random.choice(parents)]\n",
    "        parent2 = population[np.random.choice(parents)]\n",
    "        crossover_point = np.random.randint(0, X_train.shape[1])\n",
    "        child = np.hstack((parent1[:crossover_point], parent2[crossover_point:]))\n",
    "        mutation = np.random.rand(X_train.shape[1]) < mutation_rate\n",
    "        child = (child + mutation) % 2\n",
    "        new_population.append(child)\n",
    "    population = np.vstack((population[parents], new_population))\n",
    "\n",
    "best_individual = population[np.argmax(fitness_scores)]\n",
    "selected_features = np.where(best_individual == 1)[0]\n",
    "\n",
    "start_time_with_ga = time.time()\n",
    "clf = KNeighborsClassifier(n_neighbors=5)  # Set the number of neighbors (e.g., 5)\n",
    "\n",
    "start_time = time.time()\n",
    "clf.fit(X_train.iloc[:, selected_features], y_train)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "y_pred = clf.predict(X_test.iloc[:, selected_features])\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Execution Time:\", execution_time, \"seconds\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad35ae17",
   "metadata": {},
   "source": [
    "### After applying HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "56ace879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29]\n",
      "Best Score: (0.9546568627450981, 0.1556558609008789)\n",
      "Accuracy: 0.9200367647058824\n",
      "Precision: 0.9155921981017185\n",
      "Recall: 0.9200367647058824\n",
      "F1 Score: 0.9091209391582129\n",
      "Confusion Matrix:\n",
      " [[2815   33]\n",
      " [ 228  188]]\n",
      "Time taken: 15.794579982757568\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('Label', axis=1)\n",
    "y = df['Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "\n",
    "def objective_function(features):\n",
    "    start_time = time.time()\n",
    "    clf = DecisionTreeClassifier(random_state=42)\n",
    "    clf.fit(X_train[:, features], y_train)\n",
    "    y_pred = clf.predict(X_test[:, features])\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time  # Calculate elapsed time\n",
    "    return accuracy_score(y_test, y_pred), elapsed_time\n",
    "\n",
    "def hill_climbing_feature_selection(num_features, num_iterations):\n",
    "    current_features = list(range(num_features))\n",
    "    current_score = objective_function(current_features)\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "        neighbor = current_features.copy()\n",
    "        if len(neighbor) > 1:  \n",
    "            feature_to_remove = random.choice(neighbor)\n",
    "            neighbor.remove(feature_to_remove)\n",
    "        else:\n",
    "            features_not_in_subset = list(set(range(num_features)) - set(neighbor))\n",
    "            if features_not_in_subset:\n",
    "                feature_to_add = random.choice(features_not_in_subset)\n",
    "                neighbor.append(feature_to_add)\n",
    "        neighbor_score = objective_function(neighbor)\n",
    "        if neighbor_score > current_score:\n",
    "            current_features = neighbor\n",
    "            current_score = neighbor_score\n",
    "\n",
    "    return current_features, current_score\n",
    "\n",
    "\n",
    "num_features = X_train.shape[1]\n",
    "num_iterations = 100\n",
    "\n",
    "selected_features, best_score = hill_climbing_feature_selection(num_features, num_iterations)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)  \n",
    "knn.fit(X_train[:, selected_features], y_train)\n",
    "y_pred = knn.predict(X_test[:, selected_features])\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Selected Features:\", selected_features)\n",
    "print(\"Best Score:\", best_score)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Confusion Matrix:\\n\", confusion)\n",
    "print(\"Time taken: \"+str(elapsed_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
